import os
import re
import glob
import json
import ast
from huggingface_hub import hf_hub_download


def integrate_model(repo_id, files_to_download, dir_name, transformers_path="../../../../"):
    """
    é€šç”¨æ¨¡å‹é›†æˆå‡½æ•°

    å‚æ•°:
    repo_id (str): Hugging Face ä»“åº“ ID (å¦‚ "Qwen/Qwen-7B-Chat")
    files_to_download (list): éœ€è¦ä¸‹è½½çš„æ–‡ä»¶åˆ—è¡¨ (å¦‚ ["configuration.py", "modeling.py"])
    dir_name (str): æ¨¡å‹ç›®å½•åç§° (å¦‚ "qwen")
    transformers_path (str): Transformers åº“æ ¹è·¯å¾„ (é»˜è®¤ä¸º "../../../../")
    """
    # =============== æ­¥éª¤ 1: å‡†å¤‡æ¨¡å‹ç›®å½• ===============
    print("\n" + "=" * 50)
    print(f"æ­¥éª¤ 1: åˆ›å»ºæ¨¡å‹ç›®å½• '{dir_name}'")
    print("=" * 50)

    models_dir = os.path.join(transformers_path, "src/transformers/models/")
    target_dir = os.path.join(models_dir, dir_name)

    # åˆ›å»ºæ¨¡å‹ç›®å½•ï¼ˆå¦‚æœä¸å­˜åœ¨ï¼‰
    os.makedirs(target_dir, exist_ok=True)
    print(f"âœ… æ¨¡å‹ç›®å½•: {target_dir}")

    # =============== æ­¥éª¤ 2: ä¸‹è½½æ¨¡å‹æ–‡ä»¶ ===============
    print("\n" + "=" * 50)
    print(f"æ­¥éª¤ 2: ä¸‹è½½æ¨¡å‹æ–‡ä»¶ ({len(files_to_download)} ä¸ªæ–‡ä»¶)")
    print("=" * 50)

    status = download_model_files(repo_id, target_dir, files_to_download)

    if not status:
        import sys
        sys.exit()

    # =============== æ­¥éª¤ 3: åˆ›å»ºæ¨¡å‹ __init__.py ===============
    print("\n" + "=" * 50)
    print(f"æ­¥éª¤ 3: åˆ›å»ºæ¨¡å‹ __init__.py")
    print("=" * 50)

    model_classes = create_model_init_file(target_dir)
    print(f"âœ… å¯¼å‡ºçš„ç±»: {', '.join(model_classes)}")

    # =============== æ­¥éª¤ 4: æ›´æ–° models/__init__.py ===============
    print("\n" + "=" * 50)
    print(f"æ­¥éª¤ 4: æ›´æ–° models/__init__.py")
    print("=" * 50)

    models_init = os.path.join(models_dir, "__init__.py")
    update_models_init_file(dir_name, models_init)

    # =============== æ­¥éª¤ 5: æ›´æ–° transformers/__init__.py ===============
    print("\n" + "=" * 50)
    print(f"æ­¥éª¤ 5: æ›´æ–° transformers/__init__.py")
    print("=" * 50)

    top_level_init = os.path.join(transformers_path, "src/transformers/__init__.py")
    update_top_level_init_file(dir_name, model_classes, top_level_init)

    print("\n" + "=" * 50)
    print(f"âœ… æ‰€æœ‰æ­¥éª¤å®Œæˆ! '{dir_name}' æ¨¡å‹å·²æˆåŠŸé›†æˆåˆ° Transformers åº“")
    print("=" * 50)


def download_model_files(repo_id, target_dir, files_to_download):
    """ä» Hugging Face Hub ä¸‹è½½æ¨¡å‹æ–‡ä»¶"""
    print(f"ä»ä»“åº“ {repo_id} ä¸‹è½½æ–‡ä»¶åˆ° {target_dir}")

    for filename in files_to_download:
        print(f"ğŸ“¥ ä¸‹è½½: {filename}")
        try:
            # ä¸‹è½½æ–‡ä»¶åˆ°æŒ‡å®šç›®å½•
            file_path = hf_hub_download(
                repo_id=repo_id,
                filename=filename,
                local_dir=target_dir,
                repo_type="model"
            )
            print(f"âœ… ä¸‹è½½æˆåŠŸ: {os.path.basename(file_path)}")
        except Exception as e:
            print(f"âŒ ä¸‹è½½å¤±è´¥ {filename}: {str(e)}")
            # å°è¯•å¤‡ç”¨ä¸‹è½½æ–¹å¼
            print("å°è¯•å¤‡ç”¨ä¸‹è½½æ–¹å¼...")
            try:
                backup_download(repo_id, filename, target_dir)
            except Exception as e2:
                print(f"âŒ å¤‡ç”¨ä¸‹è½½ä¹Ÿå¤±è´¥: {str(e2)}")

                return False

    return True


def backup_download(repo_id, filename, target_dir):
    """å¤‡ç”¨ä¸‹è½½æ–¹å¼ï¼šç›´æ¥é€šè¿‡ URL ä¸‹è½½"""
    import requests
    url = f"https://huggingface.co/{repo_id}/resolve/main/{filename}?download=true"
    response = requests.get(url, stream=True)
    response.raise_for_status()

    file_path = os.path.join(target_dir, filename)
    with open(file_path, "wb") as f:
        for chunk in response.iter_content(chunk_size=8192):
            f.write(chunk)

    print(f"âœ… å¤‡ç”¨ä¸‹è½½æˆåŠŸ: {filename}")


def create_model_init_file(target_dir):
    """åˆ›å»ºæ¨¡å‹ç›®å½•çš„ __init__.py æ–‡ä»¶"""
    print(f"åˆ›å»º __init__.py æ–‡ä»¶")

    # æ”¶é›†æ‰€æœ‰æ¨¡å‹æ–‡ä»¶ï¼ˆé™¤äº† __init__.pyï¼‰
    model_files = glob.glob(os.path.join(target_dir, "*.py"))
    model_files = [f for f in model_files if not f.endswith("__init__.py")]

    # æå–æ‰€æœ‰å…¬å…±ç±»
    all_classes = []
    class_imports = {}

    for file_path in model_files:
        module_name = os.path.splitext(os.path.basename(file_path))[0]
        classes = extract_classes_from_file(file_path)

        if classes:
            class_imports[module_name] = classes
            all_classes.extend(classes)

    # å¦‚æœæ²¡æœ‰æå–åˆ°ç±»ï¼Œä½¿ç”¨é»˜è®¤å€¼
    if not all_classes:
        print("âš ï¸ æœªæå–åˆ°ä»»ä½•ç±»ï¼Œä½¿ç”¨å›é€€å€¼")
        # å°è¯•ä»æ–‡ä»¶åæ¨æ–­ç±»å
        default_classes = {}
        for file_path in model_files:
            name = os.path.splitext(os.path.basename(file_path))[0]
            prefix = name.split('_')[0].capitalize()
            if "config" in name:
                default_classes[name] = [f"{prefix}Config"]
            elif "model" in name:
                default_classes[name] = [
                    f"{prefix}ForCausalLM",
                    f"{prefix}Model",
                    f"{prefix}PreTrainedModel"
                ]
            elif "token" in name:
                default_classes[name] = [f"{prefix}Tokenizer"]

        if not default_classes:
            default_classes = {"modeling": ["NewModel"]}

        for module, classes in default_classes.items():
            class_imports[module] = classes
            all_classes.extend(classes)

    # ç”Ÿæˆå¯¼å…¥è¯­å¥
    import_lines = [
        f"from .{module} import {', '.join(classes)}"
        for module, classes in class_imports.items()
    ]

    # åˆ›å»º __init__.py å†…å®¹
    import_lines = "\n".join(import_lines)
    init_content = f"""# æ­¤æ–‡ä»¶ç”±è„šæœ¬è‡ªåŠ¨ç”Ÿæˆ
# è¯·å‹¿æ‰‹åŠ¨ä¿®æ”¹ï¼Œå¦‚éœ€æ›´æ–°è¯·é‡æ–°è¿è¡Œç”Ÿæˆè„šæœ¬

{import_lines}

__all__ = [
    {', '.join([f'"{c}"' for c in all_classes])}
]
"""

    # å†™å…¥æ–‡ä»¶
    init_file = os.path.join(target_dir, "__init__.py")
    with open(init_file, "w", encoding="utf-8") as f:
        f.write(init_content)

    print(f"âœ… å·²åˆ›å»º: {init_file}")

    return all_classes


def extract_classes_from_file(file_path):
    """ä» Python æ–‡ä»¶ä¸­æå–æ‰€æœ‰å…¬å…±ç±»å®šä¹‰"""
    classes = []
    try:
        with open(file_path, "r", encoding="utf-8") as f:
            content = f.read()

        # ä½¿ç”¨æ­£åˆ™è¡¨è¾¾å¼åŒ¹é…ç±»å®šä¹‰
        pattern = r"^class\s+(\w+)\s*(?:\(|:)"
        matches = re.findall(pattern, content, re.MULTILINE)

        # è¿‡æ»¤æ‰ç§æœ‰ç±»ï¼ˆä»¥_å¼€å¤´çš„ï¼‰
        classes = [m for m in matches if not m.startswith('_')]
    except Exception as e:
        print(f"âš ï¸ è§£ææ–‡ä»¶å¤±è´¥ {file_path}: {str(e)}")

    return classes


def update_models_init_file(model_name, models_init_path):
    """æ›´æ–° models/__init__.py æ–‡ä»¶"""
    if not os.path.exists(models_init_path):
        print(f"âš ï¸ æ–‡ä»¶ä¸å­˜åœ¨: {models_init_path}")
        return

    print(f"æ›´æ–° {models_init_path} ä»¥åŒ…å« {model_name} æ¨¡å‹")

    # è¯»å–æ–‡ä»¶å†…å®¹
    with open(models_init_path, "r", encoding="utf-8") as f:
        content = f.read()

    # æ£€æŸ¥æ˜¯å¦å·²å­˜åœ¨å¯¼å…¥è¯­å¥
    import_statement = f"from .{model_name} import *\n"
    if import_statement in content:
        print(f"âœ… {model_name} å·²å­˜åœ¨äº {models_init_path}")
        return

    # åœ¨æ–‡ä»¶æœ«å°¾æ·»åŠ å¯¼å…¥è¯­å¥
    with open(models_init_path, "a", encoding="utf-8") as f:
        f.write("\n")
        f.write(import_statement)

    print(f"âœ… å·²æ·»åŠ  '{import_statement.strip()}'")


def update_top_level_init_file(model_name, model_classes, top_level_path):
    """æ›´æ–°é¡¶å±‚ __init__.py æ–‡ä»¶"""
    if not os.path.exists(top_level_path):
        print(f"âš ï¸ æ–‡ä»¶ä¸å­˜åœ¨: {top_level_path}")
        return

    print(f"æ›´æ–° {top_level_path} ä»¥åŒ…å« {model_name} æ¨¡å‹")

    # è¯»å–æ–‡ä»¶å†…å®¹
    with open(top_level_path, "r", encoding="utf-8") as f:
        content = f.read()

    # æ£€æŸ¥æ˜¯å¦å·²å­˜åœ¨å¯¼å…¥è¯­å¥
    if f"from .models.{model_name} import *\n" in content:
        print(f"âœ… {model_name} å·²å­˜åœ¨äº {top_level_path}")
        return

    # å‡†å¤‡è¦è¿½åŠ çš„å†…å®¹
    key = f"models.{model_name}"
    append_content = f"""
# ===== è‡ªåŠ¨æ·»åŠ çš„æ¨¡å‹: {model_name} =====
try:
    # å°è¯•æ·»åŠ åˆ°ç°æœ‰ç»“æ„
    _import_structure["{key}"].extend(
{json.dumps(model_classes, ensure_ascii=False, indent=8)}
    )
except KeyError:
    # åˆ›å»ºæ–°ç»“æ„
    _import_structure["{key}"] = {json.dumps(model_classes, ensure_ascii=False, indent=4)}

# ç¡®ä¿åœ¨ç±»å‹æ£€æŸ¥æ—¶å¯¼å…¥
if TYPE_CHECKING:
    from .models.{model_name} import *
\n
"""
    append_content += """else:
    import sys

    _import_structure = {k: set(v) for k, v in _import_structure.items()}

    import_structure = define_import_structure(Path(__file__).parent / "models", prefix="models")
    import_structure[frozenset({})].update(_import_structure)

    sys.modules[__name__] = _LazyModule(
        __name__,
        globals()["__file__"],
        import_structure,
        module_spec=__spec__,
        extra_objects={"__version__": __version__},
    )"""
    # åœ¨æ–‡ä»¶æœ«å°¾æ·»åŠ å†…å®¹
    with open(top_level_path, "a", encoding="utf-8") as f:
        f.write(append_content)

    print(f"âœ… æˆåŠŸæ·»åŠ  {model_name} æ¨¡å‹åˆ° {top_level_path}")


if __name__ == "__main__":
    # ===================== ç”¨æˆ·é…ç½®åŒºåŸŸ =====================
    # åªéœ€ä¿®æ”¹è¿™é‡Œçš„ä¸‰ä¸ªå‚æ•°å³å¯
    REPO_ID = "THUDM/chatglm3-6b"  # Hugging Face æ¨¡å‹ä»“åº“ ID
    FILES_TO_DOWNLOAD = [  # éœ€è¦ä¸‹è½½çš„æ–‡ä»¶åˆ—è¡¨
        "configuration_chatglm.py",
        "modeling_chatglm.py",
        "tokenization_chatglm.py",
    ]
    MODEL_DIR_NAME = "chatglm3"  # æ¨¡å‹ç›®å½•åç§°ï¼ˆå°å†™ï¼‰

    # ===================== æ‰§è¡Œé›†æˆ =====================
    integrate_model(
        repo_id=REPO_ID,
        files_to_download=FILES_TO_DOWNLOAD,
        dir_name=MODEL_DIR_NAME
    )